![test cases futurama](http://www.brendanconnolly.net/wp-content/uploads/2016/03/testcasesMeme.png) 

This post is inspired by a blog post I really enjoyed recently by Colin Cherry, [A is for Apathy](https://itesting.com.au/2016/03/08/a-is-for-apathy/).  In it he describes how apathy and ego inhibit companies engaging in testing despite measurable incentive to do so. So check it out it's worth the read.

### Ego Get's In The Way

> Ego: A person's sense of self-esteem or self-importance.

Since test cases biggest selling point is the purported ability that once created they can be handed off to other testers for completion, and serve as a guide for regression testing and training. By nature they are targeted at less experienced or skilled testers and contributes to the idea that anyone can test. 

Everyone likes to feel important and like their insights are meaningful. Test cases invite the opposite connotations, testers are just bodies in seats handed what amounts to marching orders. Perform these actions as described and *check* that the behavior matches expectations. 

So what happens when a testers intuition conflicts with the expected behavior or with the process it takes to get to that point? Do they follow orders or trust their gut and risk rebuttal? I have a strong suspicion that the less secure in your testing abilities the more likely you are to try to make what you are seeing line up with test steps. 

Taking that line of reasoning a step further, once the tester succumbs to confirmation bias and starts making compromises, rationalizing the behavior of the software to satisfy the test case, how valuable do you think the overall testing process is perceived to be? 
  
Another part of the problem here is the [framing effect](http://blog.allpsych.com/the-top-cognitive-biases-influencing-your-decisions/), which loosely defined means that the way information is presented to someone affects their decisions and perceptions. Consider the implied goal when handing over a set of test cases to someone. Now think of it in terms of determining a route for a car trip. When you use GPS and turn by turn directions the trip us all about reaching the destination. When you pull out a map and start planning your route you are considering the journey as well as the journey. 

So do test scripts encourage active evaluation the software through interacting with it or do they lead the tester to focus just on completing the checklist? How do you think that effects your feelings of self-esteem and self-importance? 


### In the Philosophical Sense

> Ego:  A conscious thinking subject.
 
 If your cases are detailed enough to convey the real intent of a test and straightforward enough that even brand new hires can follow them with accuracy then how much conscious thinking about the software is the tester actually doing? Philosophically speaking test cases directly conflict with ego. Testers aren't consciously thinking subjects while executing test cases. The thinking has already been done by the person authoring the test cases. That means the people performing the tests are much closer to drones following instructions. Testing becomes a rote exercise. 

### Apathetic Execution

In both cases the effects of test cases on the ego lead to apathetic test execution. Fear maybe the mind killer, but apathy is the quality killer.
<iframe width="560" height="315" src="https://www.youtube.com/embed/kJsYKhEV6o0" frameborder="0" allowfullscreen></iframe>

Colin sums up apathy nicely in his post:
>Apathy has no energy to tap into. Apathy is like a black hole in the solar system. Apathy is usually catching, in that it >spreads like a fungus throughout organizations. Apathy is the half-brother to cynicism. Apathy sucks the life-blood out of >people.

Does that sound like a recipe for high quality testing? Even if the relationship between test cases and apathy is more correlation that causation is it really worth the risk? Do we need more people that fall into the anyone can test category performing tests? Is it not worth the time to invest in your people and you product and train new team members through pairing them with more experienced testers instead of handing them scripts? We don't have to cater to the lowest common denominator, it cheapens testing and makes it harder for other people to take testing seriously.  